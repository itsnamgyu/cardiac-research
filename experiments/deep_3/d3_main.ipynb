{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')  # don't display mpl windows (will cause error in non-gui environment)\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "import keras\n",
    "\n",
    "import core.history as ch\n",
    "import core.fine_model as cm\n",
    "from core.fine_model import FineModel\n",
    "\n",
    "import cr_interface as cri\n",
    "import keras_utils as ku\n",
    "import analysis\n",
    "from lib import Timer, notify\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# number of folds\n",
    "K = 5\n",
    "\n",
    "# save intermediate weights\n",
    "SAVE_ALL_WEIGHTS = True\n",
    "\n",
    "# interval for saving intermediate weights (in epochs)\n",
    "T = 10\n",
    "\n",
    "# multiplier for out_of_myocardial (OAP, OBS) slices\n",
    "BALANCE = 5\n",
    "\n",
    "LEARNING_RATES = [\n",
    "    0.0001, 0.00001\n",
    "]\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "# experiment index to track saved model weights, training history etc.\n",
    "# iterate this index for each run (make sure to keep track of this index)\n",
    "EXP = 4\n",
    "\n",
    "# whether to sample 10% of all slices (for sanity checking purposes)\n",
    "SAMPLE = True \n",
    "\n",
    "# seed for k-fold split\n",
    "K_SPLIT_SEED = 1\n",
    "\n",
    "# models to train\n",
    "MODEL_KEYS = [\n",
    "    #'xception',\n",
    "    'mobileneta25',\n",
    "    #'mobilenetv2a35',\n",
    "    #'vgg16',\n",
    "    #'resnet50v2',\n",
    "    #'inception_v3',\n",
    "    #'inception_resnet_v2',\n",
    "    #'densenet121',\n",
    "    #'nasnet_mobile',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_IMAGE_DIR = 'temp_image'\n",
    "\n",
    "\n",
    "def get_train_val_generators(fm: FineModel, folds):\n",
    "    \"\"\"\n",
    "    Get train/validation ImageDataGenerators for the given model for each fold.\n",
    "    Note that subsequent calls to this method will invalidate the generators\n",
    "    returned from previous calls.\n",
    "    \n",
    "    Train/validation images are BOTH BALANCED AND AUGMENTED\n",
    "    \n",
    "    :param fm: \n",
    "    The base model for which you want to use the generators\n",
    "    \n",
    "    :param folds: \n",
    "    \n",
    "    :return: \n",
    "    tuple(train_gens, val_gens)\n",
    "    \n",
    "    train_gens: list of ImageDataGenerators for the train data in each fold\n",
    "    val_gens: list of ImageDataGenerators for the validation data in each fold\n",
    "    \"\"\"\n",
    "    print('Loading Train/Val ImageDataGenerators'.center(80, '-'))\n",
    "    \n",
    "    aug_gen = fm.get_image_data_generator(augment=True)\n",
    "    \n",
    "    val_gens = []\n",
    "    train_gens = []\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "        val_dir = os.path.join(TEMP_IMAGE_DIR, 'val{}'.format(i))\n",
    "        train_dir = os.path.join(TEMP_IMAGE_DIR, 'train{}'.format(i))\n",
    "        \n",
    "        # refresh directories\n",
    "        os.makedirs(val_dir, exist_ok=True)\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        shutil.rmtree(val_dir)\n",
    "        shutil.rmtree(train_dir)\n",
    "        os.makedirs(val_dir, exist_ok=True)\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "        fold: cri.CrCollection\n",
    "        for j, fold in enumerate(folds):\n",
    "            if i == j:\n",
    "                # export validation data for fold i\n",
    "                fold.export_by_label(val_dir, balancing=5)\n",
    "            else:\n",
    "                # export train data for fold i\n",
    "                fold.export_by_label(train_dir, balancing=5)\n",
    "        \n",
    "        train_gens.append(aug_gen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=fm.get_output_shape(),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='categorical',\n",
    "        ))\n",
    "        val_gens.append(aug_gen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=fm.get_output_shape(),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='categorical',\n",
    "        ))\n",
    "        \n",
    "        print('Fold {}: {:<4} train images / {:<4} validation images'.format(\n",
    "            i + 1, train_gens[-1].n, val_gens[-1].n,\n",
    "        ))\n",
    "    \n",
    "    test_dir = os.path.join(TEMP_IMAGE_DIR, 'test')\n",
    "    for fold in folds:\n",
    "        # export test data for all\n",
    "        fold.export_by_label(test_dir, balancing=1) \n",
    "    \n",
    "    return train_gens, val_gens\n",
    "\n",
    "\n",
    "def get_test_generator(fm: FineModel, test_collection: cri.CrCollection):\n",
    "    \"\"\"\n",
    "    Get ImageDataGenerator for the test data, compatible with the given model.\n",
    "    Note that subsequent calls to this method will invalidate the generator\n",
    "    returned from previous calls.\n",
    "    \n",
    "    Test images are NOT AUGMENTED NOR BALANCED\n",
    "    \n",
    "    :param fm: \n",
    "    The base model for which you want to use the generators\n",
    "    \n",
    "    :param test_collection:\n",
    "    CrCollection containing test data\n",
    "    \n",
    "    :return: \n",
    "    ImageDataGenerator\n",
    "    \"\"\"\n",
    "    print('Loading Test ImageDataGenerator'.center(80, '-'))\n",
    "    \n",
    "    pure_gen = fm.get_image_data_generator(augment=False)\n",
    "    test_dir = os.path.join(TEMP_IMAGE_DIR, 'test')\n",
    "    \n",
    "    # refresh directories\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    shutil.rmtree(test_dir)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    test_collection.export_by_label(test_dir, balancing=1)\n",
    "    \n",
    "    print('[debug] test image count: {}'.format(test_collection.df.shape[0]))\n",
    "    \n",
    "    test_gen = pure_gen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=fm.get_output_shape(),\n",
    "        batch_size=test_collection.df.shape[0],\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "    print('Test images: {}'.format(test_gen.n))\n",
    "    \n",
    "    return test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_learning_rate(fm: FineModel, depth_index, train_gens, val_gens, test_gen):\n",
    "    \"\"\"\n",
    "    Train the fine model (frozen at some given depth) for all five folds of data,\n",
    "    and choose the optimal learning rate BASED ON THE FINAL VALIDATION ACCURACY.\n",
    "    Consider learning rates defined in the global variable LEARNING_RATES\n",
    "    \n",
    "    \n",
    "    Save model with the following KEYS: [load weights via fm.load_weights(KEY)]\n",
    "    EXP01_D01\n",
    "    Fully trained model for the optimal learning rate\n",
    "    \n",
    "    \n",
    "    :param fm:\n",
    "    FineModel to train, i.e., the base network to train on\n",
    "    \n",
    "    :param depth_index:\n",
    "    The INDEX of the \"freeze depth\" for the given FineModel\n",
    "    \n",
    "    :param train_gens\n",
    "    List of train ImageDataGenerators for each fold\n",
    "    \n",
    "    :param val_gens  \n",
    "    List of validation ImageDataGenerators for each fold\n",
    "    \n",
    "    :param val_gens  \n",
    "    Test ImageDataGenerator for each fold\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "def train_model_all_folds(fm, depth_index, lr_index,\n",
    "                          epochs, train_gens, val_gens, test_gen):\n",
    "    \"\"\"\n",
    "    Train the model (frozen at some depth) for all five folds\n",
    "\n",
    "\n",
    "    Saves intermediate models with the following KEYS: [load weights via fm.load_weights(KEY)]\n",
    "    EXP01_D01_L03_F01:\n",
    "    Fully trained model for the 1st freeze depth, 3rd learning rate, fold 1\n",
    "    EXP01_D01_L03_F01_E025:\n",
    "    Partially trained model for the 1st freeze depth, 3rd learning rate, fold 1, until the 25th epoch\n",
    "\n",
    "    Saves training history with the following KEYS: [get data via ch.get_history(model_name, KEY)]\n",
    "    EXP01_D01_L03_F01:\n",
    "    Training history for the 1st freeze depth, 3rd learning rate, fold 1\n",
    "\n",
    "\n",
    "    :param fm:\n",
    "    FineModel to train, i.e., the base network to train on\n",
    "\n",
    "    :param depth_index:\n",
    "    The INDEX of the \"freeze depth\" for the given FineModel\n",
    "\n",
    "    :param lr_index:\n",
    "    The INDEX of the learning rate, i.e., lr = LEARNING_RATES[lr_index]\n",
    "\n",
    "    :param epochs:\n",
    "    Number of epochs to train. MUST BE MULTIPLE OF 5.\n",
    "\n",
    "    :param train_gens\n",
    "    List of train ImageDataGenerators for each fold\n",
    "\n",
    "    :param val_gens\n",
    "    List of validation ImageDataGenerators for each fold\n",
    "\n",
    "    :param val_gens\n",
    "    Test ImageDataGenerator for each fold\n",
    "\n",
    "    :return:\n",
    "    tuple(val_loss, val_acc): AVERAGE validation loss and accuracy at FINAL EPOCH\n",
    "    \"\"\"\n",
    "    _exp_key = 'EXP{:02}'.format(EXP)\n",
    "    _depth_key = _exp_key + '_D{:02}'\n",
    "    _fold_key = _depth_key + '_L{:02}_F{:02}'\n",
    "    _epoch_key = _fold_key + '_E{:03}'\n",
    "\n",
    "    lr = LEARNING_RATES[lr_index]\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    # train the model K times, one for each fold\n",
    "    for i in range(K):\n",
    "        # load model at previous state\n",
    "        previous_depth_index = depth_index - 1\n",
    "        if previous_depth_index < 0:\n",
    "            fm.reload_model()\n",
    "        else:\n",
    "            fm.load_weights(_depth_key.format(previous_depth_index))\n",
    "        fm.set_depth(depth_index)\n",
    "        fm.compile_model(lr=lr)\n",
    "        model = fm.get_model()\n",
    "\n",
    "        print('[debug] batch: {}'.format(BATCH_SIZE))\n",
    "        print('[debug] size: {}'.format(train_gens[i].n))\n",
    "        print('[debug] steps: {}'.format(len(train_gens[i])))\n",
    "\n",
    "        # train T epochs at a time\n",
    "        start_epoch = 0\n",
    "        save_interval = T\n",
    "        while start_epoch < epochs:\n",
    "            print('[debug] epoch {}'.format(start_epoch))\n",
    "            target_epoch = start_epoch + save_interval\n",
    "            if target_epoch > epochs:\n",
    "                target_epoch = epochs\n",
    "            result = model.fit_generator(\n",
    "                train_gens[i],\n",
    "                validation_data=val_gens[i],\n",
    "                steps_per_epoch=len(train_gens[i]),\n",
    "                validation_steps=len(val_gens[i]),\n",
    "                workers=16,\n",
    "                use_multiprocessing=True,\n",
    "                shuffle=True,\n",
    "                epochs=target_epoch,\n",
    "                initial_epoch=start_epoch,\n",
    "            )\n",
    "            start_epoch = target_epoch\n",
    "\n",
    "            # update training history\n",
    "            ch.append_history(result.history, fm.get_name(), _fold_key.format(\n",
    "                depth_index, lr_index, i\n",
    "            ))\n",
    "            \n",
    "            if SAVE_ALL_WEIGHTS:\n",
    "                # save intermediate weights\n",
    "                fm.save_weights(_epoch_key.format(\n",
    "                    depth_index, lr_index, i, target_epoch,\n",
    "                ))\n",
    "\n",
    "        # save final weights\n",
    "        fm.save_weights(_fold_key.format(\n",
    "            depth_index, lr_index, i\n",
    "        ))\n",
    "        \n",
    "        print('[debug] test size: {}'.format(test_gen.n))\n",
    "        print('[debug] test steps: {}'.format(len(test_gen)))\n",
    "\n",
    "        loss, acc = model.evaluate_generator(\n",
    "            test_gen,\n",
    "            steps=len(test_gen),\n",
    "            #workers=4,\n",
    "            #use_multiprogressing=True,\n",
    "        )\n",
    "\n",
    "        print('[debug] test_loss={}, test_acc={}'.format(loss, acc))\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    print('Exporting analysis')\n",
    "    for metric in analysis.metric_names.keys():\n",
    "        analysis.analyze_lr(fm, fm.get_name(), depth_index, lr_index, lr, metric, exp=EXP)\n",
    "\n",
    "    total_loss = 0\n",
    "    for loss in loss_list:\n",
    "        total_loss += loss\n",
    "    avg_loss = total_loss / K\n",
    "\n",
    "    total_acc = 0\n",
    "    for acc in acc_list:\n",
    "        total_acc += acc\n",
    "    avg_acc = total_acc / K\n",
    "\n",
    "    print('[debug] avg_test_loss={}, avg_test_acc={}'.format(avg_loss, avg_acc))\n",
    "\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_stats(train, test, folds):\n",
    "    # Print stats for each train/test set\n",
    "    def print_stats(collection):\n",
    "        df = collection.df\n",
    "        print('{:<3} patients / {:<4} images'.format(df.pid.unique().shape[0], df.shape[0]))\n",
    "        print(df.label.value_counts().to_string())\n",
    "\n",
    "    print('Training/Validation Set'.center(80, '-'))\n",
    "    print_stats(train)\n",
    "\n",
    "    print('Test Set'.center(80, '-'))\n",
    "    print_stats(test)\n",
    "\n",
    "    print()\n",
    "    print('Note that OAP, OBS images in the training/validation set will be duplicated 5 times')\n",
    "    print('to solve the class imbalance issue')\n",
    "    print()\n",
    "\n",
    "    # Print number of images by fold by label (training data)\n",
    "    stats = dict()\n",
    "    for i, fold in enumerate(folds):\n",
    "        counts = fold.df.label.value_counts()\n",
    "        counts.loc['total'] = fold.df.shape[0]\n",
    "        stats[i + 1] = counts\n",
    "    stats = pd.DataFrame(stats)\n",
    "\n",
    "    print('5-Fold Training Set Data'.center(80, '-'))\n",
    "    print(stats.to_string(col_space=8))\n",
    "    print()\n",
    "\n",
    "    # Columnwise-print or cr_codes (training data)\n",
    "    cr_codes_by_fold = list(sorted(fold.df.pid.unique()) for fold in folds)\n",
    "    max_len = 0\n",
    "    for codes in cr_codes_by_fold:\n",
    "        if max_len < len(codes):\n",
    "            max_len = len(codes)\n",
    "    for i, _ in  enumerate(folds):\n",
    "        print('Fold {}'.format(i + 1).ljust(16), end='')\n",
    "    print()\n",
    "    print('-' * 80)\n",
    "    for i in range(max_len):\n",
    "        for codes in cr_codes_by_fold:\n",
    "            if i < len(codes):\n",
    "                print('{:<16d}'.format(codes[i]), end='')\n",
    "            else:\n",
    "                print('{:<16s}'.format(''), end='')\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_model(model_key, train_folds, test):\n",
    "    print(' MODEL: {} '.format(model_key).center(100, '#'))\n",
    "    keras.backend.clear_session()\n",
    "    models = FineModel.get_dict()\n",
    "    fm = models[model_key]()\n",
    "    train_gens, val_gens = get_train_val_generators(fm, train_folds)\n",
    "    test_gen = get_test_generator(fm, test)\n",
    "    for i, lr in enumerate(LEARNING_RATES):\n",
    "        print('Starting training {} lr={}'.format(fm.get_name(), lr).center(100, '-'))\n",
    "        train_model_all_folds(fm, 0, i, EPOCHS, train_gens, val_gens, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train = cri.CrCollection.load().filter_by(dataset_index=0).tri_label().labeled()\n",
    "    test = cri.CrCollection.load().filter_by(dataset_index=1).tri_label().labeled()\n",
    "    if SAMPLE:\n",
    "        train = train.sample(frac=0.1)\n",
    "        test = test.sample(frac=0.1)\n",
    "    folds = train.k_split(K, seed=K_SPLIT_SEED)\n",
    "    \n",
    "    print_all_stats(train, test, folds)\n",
    "    \n",
    "    for key in MODEL_KEYS:\n",
    "        run_on_model(key, folds, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Training/Validation Set-----------------------------\n",
      "91  patients / 252  images\n",
      "in     184\n",
      "obs     36\n",
      "oap     32\n",
      "------------------------------------Test Set------------------------------------\n",
      "56  patients / 154  images\n",
      "in     124\n",
      "obs     16\n",
      "oap     14\n",
      "\n",
      "Note that OAP, OBS images in the training/validation set will be duplicated 5 times\n",
      "to solve the class imbalance issue\n",
      "\n",
      "----------------------------5-Fold Training Set Data----------------------------\n",
      "                1        2        3        4        5\n",
      "in             33       35       48       31       37\n",
      "oap             9        3        7        7        6\n",
      "obs             2        6       10       12        6\n",
      "total          44       44       65       50       49\n",
      "\n",
      "Fold 1          Fold 2          Fold 3          Fold 4          Fold 5          \n",
      "--------------------------------------------------------------------------------\n",
      "801             3401            1101            101             201             \n",
      "2401            3901            1201            1701            1301            \n",
      "4301            4901            3001            1801            1601            \n",
      "4801            5001            3601            2801            2001            \n",
      "5501            5101            4201            2901            2601            \n",
      "5601            5201            4701            3201            2701            \n",
      "5701            5301            5901            3701            3101            \n",
      "6001            5801            6101            4001            3301            \n",
      "6301            6201            6401            4601            3501            \n",
      "9301            8801            6501            9001            4101            \n",
      "12801           9801            14101           15201           4401            \n",
      "15401           10601           15601           21501           5401            \n",
      "16101           21701           24501           23001           8901            \n",
      "28601           26801           39301           26901           24401           \n",
      "28801           40001           40101           28301           30101           \n",
      "35501           43101           42501           42001           30901           \n",
      "43701           43501           42601           42401           39401           \n",
      "44601           45301           44801           43901           39501           \n",
      "                                                                40201           \n",
      "\n",
      "####################################### MODEL: mobileneta25 ########################################\n",
      "---------------------Loading Train/Val ImageDataGenerators----------------------\n",
      "Found 436 images belonging to 3 classes.\n",
      "Found 88 images belonging to 3 classes.\n",
      "Fold 1: 436  train images / 88   validation images\n",
      "Found 444 images belonging to 3 classes.\n",
      "Found 80 images belonging to 3 classes.\n",
      "Fold 2: 444  train images / 80   validation images\n",
      "Found 391 images belonging to 3 classes.\n",
      "Found 133 images belonging to 3 classes.\n",
      "Fold 3: 391  train images / 133  validation images\n",
      "Found 398 images belonging to 3 classes.\n",
      "Found 126 images belonging to 3 classes.\n",
      "Fold 4: 398  train images / 126  validation images\n",
      "Found 427 images belonging to 3 classes.\n",
      "Found 97 images belonging to 3 classes.\n",
      "Fold 5: 427  train images / 97   validation images\n",
      "------------------------Loading Test ImageDataGenerator-------------------------\n",
      "[debug] test image count: 154\n",
      "Found 154 images belonging to 3 classes.\n",
      "Test images: 154\n",
      "------------------------------Starting training mobileneta25 lr=0.0001------------------------------\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 436\n",
      "[debug] steps: 14\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.6421 - acc: 0.3556 - val_loss: 1.2389 - val_acc: 0.3295\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 12s 833ms/step - loss: 1.5144 - acc: 0.3375 - val_loss: 1.2688 - val_acc: 0.2727\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F00_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F00.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=1.0856696367263794, test_acc=0.3311688303947449\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 444\n",
      "[debug] steps: 14\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3830 - acc: 0.4018Epoch 1/2\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3910 - acc: 0.4020 - val_loss: 1.0683 - val_acc: 0.4000\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 12s 828ms/step - loss: 1.3993 - acc: 0.3791 - val_loss: 1.0235 - val_acc: 0.4250\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F01_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F01.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=1.0142751932144165, test_acc=0.4350649416446686\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 391\n",
      "[debug] steps: 13\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 16s 1s/step - loss: 1.7556 - acc: 0.3154 - val_loss: 1.3963 - val_acc: 0.2030\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 12s 948ms/step - loss: 1.6536 - acc: 0.3468 - val_loss: 1.4105 - val_acc: 0.1579\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F02_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F02.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=1.373134970664978, test_acc=0.1753246784210205\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 398\n",
      "[debug] steps: 13\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6556 - acc: 0.3553Epoch 1/2\n",
      "13/13 [==============================] - 16s 1s/step - loss: 1.6509 - acc: 0.3616 - val_loss: 1.2661 - val_acc: 0.4206\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 12s 933ms/step - loss: 1.4651 - acc: 0.3824 - val_loss: 1.2126 - val_acc: 0.4286\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F03_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F03.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=1.2552319765090942, test_acc=0.23376622796058655\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 427\n",
      "[debug] steps: 14\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.8066 - acc: 0.3546 - val_loss: 1.1793 - val_acc: 0.3711\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 12s 843ms/step - loss: 1.4690 - acc: 0.3899 - val_loss: 1.0127 - val_acc: 0.5773\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F04_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L00_F04.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=1.3056989908218384, test_acc=0.3311688303947449\n",
      "Exporting analysis\n",
      "Analyzing mobileneta25 D=0, LR=0.0001\n",
      "Analyzing mobileneta25 D=0, LR=0.0001\n",
      "Analyzing mobileneta25 D=0, LR=0.0001\n",
      "Analyzing mobileneta25 D=0, LR=0.0001\n",
      "[debug] avg_test_loss=1.2068021535873412, avg_test_acc=0.3012987017631531\n",
      "------------------------------Starting training mobileneta25 lr=1e-05-------------------------------\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 436\n",
      "[debug] steps: 14\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.6389 - acc: 0.3519Epoch 1/2\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 17s 1s/step - loss: 1.6265 - acc: 0.3512 - val_loss: 2.0329 - val_acc: 0.1364\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 12s 851ms/step - loss: 1.7368 - acc: 0.3225 - val_loss: 1.9758 - val_acc: 0.1136\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F00_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F00.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=2.6663272380828857, test_acc=0.10389610379934311\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 444\n",
      "[debug] steps: 14\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 17s 1s/step - loss: 2.0052 - acc: 0.3268 - val_loss: 1.7784 - val_acc: 0.3125\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 12s 863ms/step - loss: 1.9595 - acc: 0.3262 - val_loss: 1.7847 - val_acc: 0.3000\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F01_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F01.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=2.6330406665802, test_acc=0.12337662279605865\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 391\n",
      "[debug] steps: 13\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.6479 - acc: 0.3311Epoch 1/2\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 17s 1s/step - loss: 1.6272 - acc: 0.3444 - val_loss: 1.1033 - val_acc: 0.4060\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 12s 933ms/step - loss: 1.5573 - acc: 0.3772 - val_loss: 1.1033 - val_acc: 0.4135\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F02_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F02.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=1.0089411735534668, test_acc=0.4740259647369385\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 398\n",
      "[debug] steps: 13\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.9553 - acc: 0.3066 - val_loss: 1.3737 - val_acc: 0.3651\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 12s 952ms/step - loss: 1.7880 - acc: 0.3047 - val_loss: 1.4318 - val_acc: 0.2857\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F03_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F03.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=2.2137112617492676, test_acc=0.07792207598686218\n",
      "Loading model mobileneta25... complete!\n",
      "[debug] batch: 32\n",
      "[debug] size: 427\n",
      "[debug] steps: 14\n",
      "[debug] epoch 0\n",
      "Epoch 1/2\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.6111 - acc: 0.3376Epoch 1/2\n",
      "14/14 [==============================] - 18s 1s/step - loss: 1.6100 - acc: 0.3374 - val_loss: 1.4386 - val_acc: 0.3814\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 12s 854ms/step - loss: 1.6676 - acc: 0.3182 - val_loss: 1.4706 - val_acc: 0.3814\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F04_E002.hd5...complete!\n",
      "Saving weights to /Users/release/.ho/cardiac-research/core/.fine_model_weights/mobileneta25/EXP04_D00_L01_F04.hd5...complete!\n",
      "[debug] test size: 154\n",
      "[debug] test steps: 1\n",
      "[debug] test_loss=0.6519903540611267, test_acc=0.798701286315918\n",
      "Exporting analysis\n",
      "Analyzing mobileneta25 D=0, LR=1e-05\n",
      "Analyzing mobileneta25 D=0, LR=1e-05\n",
      "Analyzing mobileneta25 D=0, LR=1e-05\n",
      "Analyzing mobileneta25 D=0, LR=1e-05\n",
      "[debug] avg_test_loss=1.8348021388053894, avg_test_acc=0.3155844107270241\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    main()\n",
    "except Exception as e:\n",
    "    error = traceback.format_exc()\n",
    "    error += '\\n'\n",
    "    error += str(e)\n",
    "    print(error)\n",
    "    notify(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
