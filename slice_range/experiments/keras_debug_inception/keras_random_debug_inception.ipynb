{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../..')\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import cr_interface as cri\n",
    "import keras_utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 37\n",
    "def reset_random():\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    tf.set_random_seed(SEED)\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mobilenet': <keras_utils.Application at 0x12ba006d8>,\n",
       " 'mobilenetv2': <keras_utils.Application at 0x12c403cc0>,\n",
       " 'inceptionresnetv2': <keras_utils.Application at 0x12c403c18>,\n",
       " 'inceptionv3': <keras_utils.Application at 0x12c403c50>,\n",
       " 'nasnet': <keras_utils.Application at 0x12c403d68>,\n",
       " 'resnet50': <keras_utils.Application at 0x12c403da0>,\n",
       " 'vgg16': <keras_utils.Application at 0x12c403dd8>,\n",
       " 'vgg19': <keras_utils.Application at 0x12c403e10>,\n",
       " 'xception': <keras_utils.Application at 0x12c403e48>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ku.applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "application = ku.applications['vgg19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = cri.DATA_DIRS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators():\n",
    "    transform_parameters = {\n",
    "        'zx': 0.6,\n",
    "        'zy': 0.6,\n",
    "    }\n",
    "    zoom_gen = ImageDataGenerator()\n",
    "    zoom = lambda x: zoom_gen.apply_transform(x, transform_parameters)\n",
    "\n",
    "    generators = dict()\n",
    "    for split in splits:\n",
    "        if split == 'test':\n",
    "            augment_kwargs = dict()\n",
    "        else:\n",
    "            augment_kwargs = dict(\n",
    "                rotation_range=45,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "\n",
    "        generators[split] = ImageDataGenerator(\n",
    "            **augment_kwargs,\n",
    "            #preprocessing_function=zoom)\n",
    "        )\n",
    "\n",
    "    return generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterators():\n",
    "    generators = get_generators()\n",
    "\n",
    "    iterators = dict()\n",
    "\n",
    "    kwargs = dict(\n",
    "        target_size=application.image_size,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=SEED)\n",
    "\n",
    "    for split, gen in generators.items():\n",
    "        iterators[split] = gen.flow_from_directory(\n",
    "            directory=cri.DATA_DIRS[split],\n",
    "            **kwargs)\n",
    "        \n",
    "    return iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling Randomness\n",
    "- New sequential model from seed reproducable\n",
    "- Save/load/attach top model (with same, reproducable results)\n",
    "- Save/load/attach randomly trained top model (testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(iterator, multiplier=1):\n",
    "    # reset seed parameters\n",
    "    # note that you need to use the same iterator to reproduce order\n",
    "    iterator.total_batches_seen = 0\n",
    "    iterator.batch_index = 0\n",
    "    \n",
    "    labels = None\n",
    "    for i, batch in enumerate(iterator):\n",
    "        if i == int(len(iterator) * multiplier):\n",
    "            break\n",
    "        if labels is None:\n",
    "            labels = np.array(batch[1])\n",
    "        else:\n",
    "            labels = np.append(labels, np.array(batch[1]), axis=0)\n",
    "            \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 3 classes.\n",
      "Found 472 images belonging to 3 classes.\n",
      "Found 1682 images belonging to 3 classes.\n",
      "loading vgg19 model\n",
      "8/8 [==============================] - 38s 5s/step\n",
      "15/15 [==============================] - 63s 4s/step\n",
      "53/53 [==============================] - 224s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# create bottlenecks & save\n",
    "iterators = get_iterators()\n",
    "bottlenecks = dict()\n",
    "labels = dict()\n",
    "application.free_model()\n",
    "\n",
    "kwargs = dict(\n",
    "    verbose=1,\n",
    "    workers=8,\n",
    "    use_multiprocessing=True)\n",
    "\n",
    "for split, it in iterators.items():\n",
    "    bottlenecks[split] = application.get_model().predict_generator(it, steps=len(it), **kwargs)\n",
    "    labels[split] = get_labels(it)\n",
    "    \n",
    "LOADED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Bottlenecks\n",
    "for split, data in bottlenecks.items():\n",
    "    np.save(open('b_{}'.format(split), 'wb'), data)\n",
    "    \n",
    "for split, data in labels.items():\n",
    "    np.save(open('l_{}'.format(split), 'wb'), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bottlenecks\n",
    "bottlenecks = dict()\n",
    "labels = dict()\n",
    "for split in splits:\n",
    "    bottlenecks[split] = np.load(open('b_{}'.format(split), 'rb'))\n",
    "    labels[split] = np.load(open('l_{}'.format(split), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'validation', 'train'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottlenecks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'validation', 'train'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No problem with bottleneck save / load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=sgd,\n",
    "        #optimizer='rmsprop',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_model(compiled=True):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=application.get_model().output_shape[1:]))\n",
    "    model.add(Dense(1024,\n",
    "                        activation='relu',\n",
    "                        kernel_initializer=keras.initializers.glorot_uniform(seed=SEED)))\n",
    "    model.add(Dropout(0.5,\n",
    "                         seed=SEED))\n",
    "    model.add(Dense(3, \n",
    "                        activation='softmax',\n",
    "                        kernel_initializer=keras.initializers.glorot_uniform(seed=SEED)))\n",
    "\n",
    "    if compiled:\n",
    "        compile_model(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_random()\n",
    "top_model = load_model()\n",
    "bottle_predictions = top_model.predict(bottlenecks['test'], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bottlenecks['validation'])\n",
    "len(labels['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 512)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottlenecks['validation'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1682 samples, validate on 472 samples\n",
      "Epoch 1/10\n",
      "1682/1682 [==============================] - 11s 7ms/step - loss: 2.0212 - acc: 0.7937 - val_loss: 1.8883 - val_acc: 0.8114\n",
      "Epoch 2/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.8190 - acc: 0.9233 - val_loss: 2.1410 - val_acc: 0.8072\n",
      "Epoch 3/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.5009 - acc: 0.9524 - val_loss: 2.3769 - val_acc: 0.7924\n",
      "Epoch 4/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.4072 - acc: 0.9649 - val_loss: 2.0837 - val_acc: 0.8030\n",
      "Epoch 5/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.2772 - acc: 0.9762 - val_loss: 2.3148 - val_acc: 0.7987\n",
      "Epoch 6/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.2387 - acc: 0.9792 - val_loss: 2.3463 - val_acc: 0.7797\n",
      "Epoch 7/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.1970 - acc: 0.9863 - val_loss: 2.5831 - val_acc: 0.7669\n",
      "Epoch 8/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.1994 - acc: 0.9851 - val_loss: 2.2596 - val_acc: 0.7860\n",
      "Epoch 9/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.1862 - acc: 0.9881 - val_loss: 2.5030 - val_acc: 0.7648\n",
      "Epoch 10/10\n",
      "1682/1682 [==============================] - 6s 3ms/step - loss: 0.1838 - acc: 0.9881 - val_loss: 2.2997 - val_acc: 0.7839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167f834a8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset_random()\n",
    "top_model = load_model()\n",
    "top_model.fit(bottlenecks['train'], labels['train'],\n",
    "              validation_data=(bottlenecks['validation'], labels['validation']),\n",
    "              shuffle=True,\n",
    "              batch_size=32,\n",
    "              epochs=10)\n",
    "#top_model.save_weights('temp_inc.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "0.7330677290836654\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(labels['test']))\n",
    "count = 0\n",
    "for l in labels['test']:\n",
    "    if l[0] == 1:\n",
    "        count += 1\n",
    "print(count / len(labels['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 552us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0578135408728246, 0.8167330667792089]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.evaluate(bottlenecks['test'], labels['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472/472 [==============================] - 0s 481us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2996570053747143, 0.783898306094994]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.evaluate(bottlenecks['validation'], labels['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for element in top_model.get_weights():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_random()\n",
    "top_model = load_model()\n",
    "top_model.fit(bottlenecks['train'], labels['train'],\n",
    "              validation_data=(bottlenecks['validation'], labels['validation']),\n",
    "              shuffle=True,\n",
    "              batch_size=32,\n",
    "              epochs=1)\n",
    "top_model.save_weights('temp.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1 = top_model.predict(bottlenecks['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_model = load_model(compiled=False)\n",
    "top_model.load_weights('temp.hdf5')\n",
    "compile_model(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p2 = top_model.predict(bottlenecks['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterators = get_iterators() reuse\n",
    "reset_random()\n",
    "model = Sequential()\n",
    "application.free_model()\n",
    "pre_model = application.get_model()\n",
    "for layer in pre_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(pre_model)\n",
    "top_model = load_model(compiled=False)\n",
    "top_model.load_weights('temp.hdf5')\n",
    "model.add(top_model)\n",
    "compile_model(model)\n",
    "\n",
    "iterators = get_iterators()\n",
    "p3 = model.predict_generator(iterators['test'], verbose=1)\n",
    "p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterators = get_iterators() reuse\n",
    "model = Sequential()\n",
    "application.free_model()\n",
    "pre_model = application.get_model()\n",
    "for layer in pre_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(pre_model)\n",
    "top_model = load_model()\n",
    "model.add(top_model)\n",
    "\n",
    "sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "image_predictions = model.predict_generator(iterators['train'], verbose=1)\n",
    "    \n",
    "if False:\n",
    "    model.fit_generator(iterators['train'],\n",
    "                               validation_data=iterators['validation'],\n",
    "                               shuffle=True,\n",
    "                               epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#iterators = get_iterators() reuse\n",
    "model = Sequential()\n",
    "pre_model = application.get_model()\n",
    "for layer in pre_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(pre_model)\n",
    "top_model = load_model()\n",
    "model.add(top_model)\n",
    "model.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "image_predictions = model.predict_generator(iterators['train'], verbose=1)\n",
    "    \n",
    "if False:\n",
    "    model.fit_generator(iterators['train'],\n",
    "                               validation_data=iterators['validation'],\n",
    "                               shuffle=True,\n",
    "                               epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "pre_model = application.get_model()\n",
    "for layer in pre_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(pre_model)\n",
    "sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "image_predictions = model.predict_generator(iterators['test'], verbose=1)\n",
    "image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "pre_model = application.get_model()\n",
    "for layer in pre_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(pre_model)\n",
    "sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "image_predictions0 = model.predict_generator(iterators['test'], verbose=1)\n",
    "image_predictions0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "pre_model = application.get_model()\n",
    "model.add(pre_model)\n",
    "sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "image_predictions1 = model.predict_generator(iterators['test'], verbose=1)\n",
    "image_predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#iterators = get_iterators() reuse\n",
    "for it in iterators:\n",
    "    it.batch_index = 0\n",
    "    it.total_batches_seen = 0\n",
    "model = Sequential()\n",
    "pre_model = application.get_model()\n",
    "for layer in pre_model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(pre_model)\n",
    "top_model = load_model(compiled=False)\n",
    "model.add(top_model)\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    print(layer.trainable)\n",
    "\n",
    "if False:\n",
    "    sgd = optimizers.SGD(lr=1.0e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=sgd,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.fit_generator(iterators['train'],\n",
    "                               validation_data=iterators['validation'],\n",
    "                               shuffle=True,\n",
    "                               epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_model.evaluate(bottlenecks['test'], labels['test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
