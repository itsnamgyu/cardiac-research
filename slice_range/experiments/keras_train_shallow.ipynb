{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras_applications import vgg16, vgg19, inception_v3, resnet50, mobilenet, mobilenet_v2, inception_resnet_v2, xception, densenet, nasnet\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bottlenecks_and_labels(model, image_shape, augment_factor):\n",
    "    '''\n",
    "    Self Explanatory\n",
    "    \n",
    "    Arguments\n",
    "    - model: keras.model.Model, usually a pre-existing model excluding top-layers,\n",
    "             with pre-trained weights\n",
    "    - image_shape: tuple(x, y)\n",
    "    - augment_factor: how many times to augment non-test images\n",
    "    \n",
    "    Returns a tuple of 2 elements\n",
    "    - bottlenecks: dict of bottleneck np.ndarrays, by dataset\n",
    "    - labels: dict of label np.ndarrays, by dataset\n",
    "    '''\n",
    "    \n",
    "    # define augmenations\n",
    "    transform_parameters = {\n",
    "        'zx': 0.6,\n",
    "        'zy': 0.6,\n",
    "    }\n",
    "    zoom_gen = ImageDataGenerator()\n",
    "    zoom = lambda x: zoom_gen.apply_transform(x, transform_parameters)\n",
    "    \n",
    "    aug_gens = dict()\n",
    "    aug_gens['train'] = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            fill_mode='nearest',\n",
    "            preprocessing_function=zoom)\n",
    "    aug_gens['validation'] = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            fill_mode='nearest',\n",
    "            preprocessing_function=zoom)\n",
    "    aug_gens['test'] = ImageDataGenerator(\n",
    "            preprocessing_function=zoom)\n",
    "    \n",
    "    # get generator per dataset\n",
    "    ordered_gens = dict()\n",
    "    kwargs = dict(\n",
    "        target_size=image_shape,\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False\n",
    "    )\n",
    "    for key, aug_gen in aug_gens.items():\n",
    "        ordered_gens[key] = aug_gen.flow_from_directory(\n",
    "            '../data/data/{}'.format(key), **kwargs)\n",
    "    \n",
    "    # generate bottleneck labels after augmentation\n",
    "    labels = dict()\n",
    "    for key, gen in ordered_gens.items():\n",
    "        if key == 'test':\n",
    "            labels[key] = gen.classes\n",
    "        else:\n",
    "            labels[key] = np.tile(gen.classes, augment_factor)\n",
    "\n",
    "    # generate bottlenecks by dataset\n",
    "    kwargs = dict(\n",
    "        verbose=1,\n",
    "        workers=8,\n",
    "        use_multiprocessing=True,\n",
    "    )\n",
    "\n",
    "    bottlenecks = dict()\n",
    "    for key, gen in ordered_gens.items():\n",
    "        print('Preparing {} bottlenecks'.format(key))\n",
    "        bottlenecks[key] = model.predict_generator(\n",
    "            gen, steps=len(labels[key]), **kwargs\n",
    "        )\n",
    "\n",
    "    return bottlenecks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_shape(image_shape):\n",
    "    '''\n",
    "    Get input shape of conv-nets based on keras backend settings\n",
    "    \n",
    "    Returns\n",
    "    tuple(n1, n2, n3)\n",
    "    '''\n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        return (3,) + image_shape \n",
    "    else:\n",
    "        return image_shape + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = mobilenet.MobileNet(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=get_input_shape(IMAGE_SHAPE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(pre_model_func, image_shape, name='tune'):\n",
    "    pre_model = pre_model_func(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=get_input_shape(image_shape)\n",
    "    )\n",
    "    \n",
    "    bottlenecks, labels = generate_bottlenecks_and_labels(\n",
    "        pre_model, image_shape, augment_factor=5)\n",
    "\n",
    "    for key, val in bottlenecks.items():\n",
    "        np.save(open('bottlenecks_{}_{}.npy'.format(name, key), 'wb'), val)\n",
    "\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=pre_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(3, activation='softmax'))\n",
    "    top_model.compile(loss='categorical_crossentropy',\n",
    "                      #optimizer=optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                      #optimizer=optimizers.SGD(lr=0.01, momentum=0.9),\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    # one-hot labels\n",
    "    hot_labels = dict()\n",
    "    for key, label_array in labels.items():\n",
    "        hot_labels[key] = to_categorical(label_array, num_classes=3)\n",
    "\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "    \n",
    "    # train model\n",
    "    batch_size = 16\n",
    "    top_model.fit(bottlenecks['train'], hot_labels['train'],\n",
    "                  validation_data=(bottlenecks['validation'], hot_labels['validation']),\n",
    "                  epochs=25,\n",
    "                  batch_size=batch_size,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[tensorboard])\n",
    "\n",
    "    # evaluate model\n",
    "    results = top_model.evaluate(bottlenecks['test'], hot_labels['test'])\n",
    "\n",
    "    # save weights for model\n",
    "    top_model.save_weights('weights_{}.h5'.format(name))\n",
    "    \n",
    "    print(name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (mobilenet.MobileNet, (224, 224), 'mobilenet'),\n",
    "    (mobilenet_v2.MobileNetV2, (224, 224), 'mobilenetv2'),\n",
    "    (inception_resnet_v2.InceptionResNetV2, (299, 299), 'inceptionresnetv2'),\n",
    "    (inception_v3.InceptionV3, (299, 299), 'inceptionv3'),\n",
    "    #(densenet.DenseNet, (224, 224), 'densenet'),\n",
    "    (nasnet.NASNet, (224, 224), 'nasnet'),\n",
    "    (resnet50.ResNet50, (224, 224), 'resnet50'),\n",
    "    (vgg16.VGG16, (224, 224), 'vgg16'),\n",
    "    (vgg19.VGG19, (224, 244), 'vgg19'),\n",
    "    (xception.Xception, (299, 299), 'xception'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_and_eval(mobilenet.MobileNet, (224, 224), 'mobilenet')\n",
    "for model, shape, name in models:\n",
    "    train_and_eval(model, shape, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft Code...\n",
    "Two-layer tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_model = mobilenet.MobileNet(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=get_input_shape(IMAGE_SHAPE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "for layer in pre_model.layers[:-3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(pre_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=pre_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "new_model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_model.load_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  #optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "transform_parameters = {\n",
    "    'zx': 0.6,\n",
    "    'zy': 0.6,\n",
    "}\n",
    "zoom_gen = ImageDataGenerator()\n",
    "zoom = lambda x: zoom_gen.apply_transform(x, transform_parameters)\n",
    "gen = ImageDataGenerator(\n",
    "        preprocessing_function=zoom)\n",
    "aug_gen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=zoom)\n",
    "aug_gen2 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=zoom)\n",
    "\n",
    "train_image_generator = aug_gen.flow_from_directory(\n",
    "    '../data/data/train',\n",
    "    target_size=(IMAGE_SHAPE),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_image_generator = aug_gen2.flow_from_directory(\n",
    "    '../data/data/validation',\n",
    "    target_size=(IMAGE_SHAPE),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_image_generator = gen.flow_from_directory(\n",
    "    '../data/data/test',\n",
    "    target_size=(IMAGE_SHAPE),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 50\n",
    "new_model.fit_generator(\n",
    "    train_image_generator,\n",
    "    epochs=epoch_count,\n",
    "    validation_data=validation_image_generator,\n",
    "    workers=8,\n",
    "    use_multiprocessing=True)\n",
    "current_epoch += epoch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.evaluate_generator(test_image_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model.predict_generator(train_image_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
